1--redis是个单线程程序，但是为什么能处理那么多的并发客户端连接？

	多路复用，select，非阻塞io

I/O 多路复用技术，一个线程处理多个连接，该线程轮询每个连接，如果某个连接有请求则处理请求，没有请求则处理下一个连接

select-->poll-->epoll  

 link https://www.jianshu.com/p/78cedbd8591d

2--redis的持久化
	方式一:rdb(快照)
		内存快照必须要求redis进行文件IO操作，但是文件IO操作不能使用多路复用API
		机制是多进程Copy On Write fork出一个子进程，快照持久化完全交给子进程来处理。
		linux中父子进程
		子进程可以看到父进程中的数据 通过export
		但是子进程和父进程之间不能进行互相影响 即子进程的修改不会影响到父进程 父进程的修改不会影响到子进程
		弊端:不支持拉链 只有一个dump.db  容易丢失数据
		优点:类似java的序列化 恢复的速度较快
	方式二:aof
		aof日志存储的是redis服务器的顺序指令序列，只记录被内存进行修改的指令记录
		模式1:appendfsync always：每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢
		模式2:appendfsync no：不进行fsync，将flush文件的时机交给OS决定，速度最快
		模式3:appendfsync everysec：折中的做法，交由后台线程每秒fsync一次
		弊端:体量会变的很大(记录的是写操作) 恢复很慢
        优点:丢失数据少

        aof是文件存在 当redis发生写操作时需要对aof文件进行写操作 实际上时写道了一个内存缓存中 然后内存异步将其刷回磁盘
        但是如果突然宕机 会出现日志丢失

        fsync函数可以指定指定将文件的内容强制从缓存刷到磁盘 只要redis调用该函数就可以保证aof日志不丢失 但是fsync是一个磁盘操作

        很慢 所以需要权衡多久执行一次

        三种选择:1--永远不 让操作系统决定何时刷 2--一条指令刷一次 3--设置周期 一般在生产环境是每隔1s左右执行一次fsync

		4.0以前 重写aof 合并重复的指令 删除抵消的指令 最终还是一个纯指令的文件
		4.0以后 也是重写 发生重写之后混合rdb和aof  rdb+rdb(开始到结束之间产生的)aof 这样就会比单纯使用aof快很多

		AOF 后台执行的方式和 RDB 有类似的地方，fork 一个子进程，主进程仍进行服务
		子进程执行 AOF 持久化，数据被 dump 到磁盘上。与 RDB 不同的是，后台子进程持久化过程中
		主进程会记录期间的所有数据变更（主进程还在服务），并存储在 server.aof_rewrite_buf_blocks 中
		后台子进程结束后，redis 更新缓存追加到 AOF 文件中，是 RDB 持久化所不具备的.



		redis是先执行指令再将日志存盘 不同于其他存储引擎
		1--1.仅仅是因为，由于AOF文件会比较大，为了避免写入无效指令（错误指令）
		2--Redis 的数据是存内存的，断电之后就丢了 所以可以先执行，再记AOF
		3--redis的事务比起mysql等数据库的事务机制来说，可以称为弱事务 如果先写日志，同样会有很多无效命令。

	持久化主要在从节点进行
	
	redis4.0混合持久化
	将rdb文件的内容和增量的AOF日志文件存在一起，这里的AOF日志不再是全量的日志，而是至持久化开始到持久化结束的这段时间发生的
	增量AOF日志，通常这部分AOF日志很小

	单机 单节点 单实例
    1-单点故障
    2-容量有限
    3-压力

    主从复制
    主节点接受请求，进行读写 同步给从节点
    如何保持主从数据的同步
    强一致性:所需节点阻塞直到全部一致
    弱一致性:
    主节点异步同步数据到从节点 会丢失部分数据 redis使用的是这种
    最终一致性:主节点将数据写到中间容器，例如kafka(不是说redis就是这么干的)，客户端从kafka消费消息达到最终一致 hdfs使用的是这种

    n/2+1

    一般使用奇数台

    Cap

    Redis使用默认的异步复制，其特点是低延迟和高性能


   主从同步(主要是解决单点故障)
   从节点刚加入近集群时，必须先进行一次快照同步
   快照同步:先在主节点做一次bgsave 将快照文件传输到从节点 从节点先删除old data，进行全量加载


   通过命令 replicaof 设置追随的主节点的地址


   旧版本的命令是slaveof

   主节点可以看到有哪些从节点连接上了

   从节点不想追随主节点，可以使用replicaof no one

   人工作方式重新选择新的主节点

   然后再将剩下的节点追随新的主节点

   增量同步
   主节点写入本地内存的buffer，buffer是有限的环形数组 如果因为网络问题，从节点和主节点无法同步，那么网络恢复时，有些在主节点中的增量指令已经被覆盖了 就需要快照同步

   在进行快照同步的时候如果时间过长或者buffer太小，会导致同步期间的增量指令被覆盖，导致快照结束狗无法进行增量复制，然后会再次发起快照同步 所以需要设置一个合适的buffer 避免快照复制的死循环


   通过一个配置文件 然后使用
   redis-server ./xx.conf --sentinel redis官网有一个最简版的配置 在redis的源码解压包里面也有一个默认的哨兵的配置文件


   启动三个redis实例 启动三个哨兵 杀掉主节点 哨兵会等待一段时间开启投票 多数投票投出新的主节点 其余的将追随新的主节点

   哨兵可以从主节点那里知道从节点的信息，那么是如何知道其他哨兵的信息的?

   是使用redis自带的发布订阅

   集群(主要是解决容量问题)
   1--key % redis 数目 问题是扩容时redis数目变化 那么所有缓存的位置都会发生改变
   2--一致性hash 也是取模  一致性的Hash算法是对2的32方取模
   一致性Hash算法将整个Hash空间组织成一个虚拟的圆环，Hash函数的值空间为0 ~ 2^32 - 1(一个32位无符号整型)
   https://www.jianshu.com/p/528ce5cd7e8f
   数据倾斜问题
   在一致性Hash算法服务节点太少的情况下，容易因为节点分布不均匀面造成数据倾斜（被缓存的对象大部分缓存在某一台服务器上）问题
   为了解决数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。


   codis
   tw
   predixy
   cluster



3--redis过期策略
	方式一:惰性过期
		访问这个key的时候检查如果过期则立刻删除
	
	方式二:定时扫描(贪心策略)
		不会一次扫描过期字典中的所有的key
		1--从过期字典中随机选出20个key
		2--删除这20个key中已经过期的key
		3--如果过期的key的比例超过1/4，那就重复步骤1 
	扫描时间上限：25ms
	如果大量的key在统一时刻过期会导致客户端的请求会等待至少25ms后才进行处理
	如果客户端的超时时间设置的很短比如10ms，那么久会出现大量的链接因为超时而关闭	
	所以如果有大批量的key过期，要给过期时间设置一个随机范围，而不能全部在同一时间过期
		

	从节点:
	从节点不会进行过期扫描，主节点在key到期之后，会在AOF文件里增加一条del指令，同步
	所有的从节点
		
4--redis的内存淘汰策略
	策略1:noeviction.当内存不足以容纳新写入数据时，新写入操作会报错.读请求可以继续
	
	策略2:volatile-lru当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。

	策略3:volatile-random当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
	
	策略4:volatile-ttl 当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。
	
	策略5:allkeys-lru 当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。

	策略6:allkeys-random 当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。

5--管道
	本质:客户端通过改变了读写顺序带来的性能的巨大提升,和服务端没有什么直接关系
	客户端将请求传送给服务器，服务器处理完毕后，再将响应回复给客户端，这要花费一个网络数据包来回的时间
	如果连续执行多条指令，那么就会花费多个网络数据包来回的时间 write-->read---> write-->read
	如果调整读写顺序，write-- >write-->read-->read
	这样多个请求只会花费一次网络开销

	docker exec -it redis  redis-benchmark -t set -q 对普通的set进行压测 qps大约3w/s 阿里云服务器，1核2g


6--一个最简单的分布式锁
                "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
	这个lua脚本的意思是:获取redis中key为lockKey的值，如果和requestId相等的话则删除，否则啥都不做

redis的数据结构

String (Simple Dynamic String)

struct sdshdr {

    // buf 中已占用空间的长度
    int len;

    // buf 中剩余可用空间的长度
    int free;

    // 数据空间
    char buf[];
};

redis的字符串有2种存储方式 embstr(长度比较短的时候) raw(长度比较短)


hash
使用了一种叫做渐进式哈希(rehashing)的机制来提高字典的缩放效率，避免 rehash 对服务器性能造成影响
渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上
从而避免了集中式 rehash 而带来的庞大计算量

https://www.cnblogs.com/williamjie/p/11205593.html

在redis的实现中，没有集中的将原有的key重新rehash到新的槽中，而是分解到各个命令的执行中，以及周期函数中

在redis中每一个增删改查命令中都会判断数据库字典中的哈希表是否正在进行渐进式rehash，如果是则帮助执行一次

redis还有定时任务进行rehash


服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1（即元素的个数已经超过了一维数组 但是在bgsave 为了减少内存页的过多分离 不会扩容）

服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5（即元素的个数已经超过了一维数组的五倍 那么强制扩容）

以下是哈希表渐进式 rehash 的详细步骤：

（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。

（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。

（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。

（4）随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。

渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。

因为在进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行

 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。


另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作

 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。

ziplist
zset和hash在元素个数较少的时候采用ziplist存储

压缩列表（ziplist）本质上就是一个字节数组，是Redis为了节约内存而设计的一种线性数据结构，可以包含任意多个元素，每个元素可以是一个字节数组或一个整数。

压缩列表时一块连续的内存空间 元素之间紧挨着存储

typedef struct ziplist<T>{
...
int32 zltail_offset 压缩列表尾元素相对于压缩列表起始地址的偏移量 用于快速定位到最后一个元素

T[] entries
....
}

struct entry{
int<var> prevlen 前一个entry的长度 从后往前遍历的时候可以用来定位下一个元素 如果内容小于254字节 prevlen就用1字节存储

否则就用5字节存储

级联更新 如果某个entry经过操作从253字节变成了254字节 那么下一个entry的prevlen就需要更新 如果后面的entry的长度也是253 那么也要更新....

..

..
}

增加元素
由于ziplist是数组 意味着插入一个新的元素就需要扩展内存 所以不适合存储大型字符串 存储的元素也不宜过多


quicklist
list早期使用的是ziplist(元素多的时候) 和linkedlist(元素少的时候) 由于链表的附加空间后面使用quicklist

quicklist将linkedlist按段切分 每一段使用ziplist让存储紧凑 多个ziplist之间使用双向指针存储

跳表 看下在Algo种的实现

redis5.0 listpack

typedef struct listpack<T>{
       int32 total_bytes
       int16 size
       T[] entries
       int8 end
}
相比于ziplist 少了tail字段

typedef struct lpentry<T>{
        int<var> encoding
        optional byte[] content
        int<var> length 记录的是本entry的长度
}

listpack是对ziplist的改进，它比ziplist少了一个定位最后一个元素的属性（最后一个元素距离起始偏移量）
listpack无需这个字段辅助逆序遍历。它的entry将长度字段放在了尾部，且记录的是本entry的长度
有了它就可以快速定位前一个entry的末尾，依然可以逆序遍历（在listpack定位到最后一个元素只需要
总长度减去最后一个entry的长度即可）。这样本entry的属性不会出现在其他entry中了，消除了级联更新。
但listpack目前只用在stream中。



