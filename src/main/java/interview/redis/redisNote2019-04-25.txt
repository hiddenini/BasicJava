1--redis是个单线程程序，但是为什么能处理那么多的并发客户端连接？

	多路复用，select，非阻塞io

I/O 多路复用技术，一个线程处理多个连接，该线程轮询每个连接，如果某个连接有请求则处理请求，没有请求则处理下一个连接

select-->poll-->epoll  

 link https://www.jianshu.com/p/78cedbd8591d

2--redis的持久化
	方式一:rdb(快照)
		内存快照必须要求redis进行文件IO操作，但是文件IO操作不能使用多路复用API
		机制是多进程Copy On Write fork出一个子进程，快照持久化完全交给子进程来处理。
		linux中父子进程
		子进程可以看到父进程中的数据 通过export
		但是子进程和父进程之间不能进行互相影响 即子进程的修改不会影响到父进程 父进程的修改不会影响到子进程
		弊端:不支持拉链 只有一个dump.db  容易丢失数据
		优点:类似java的序列化 恢复的速度较快
	方式二:aof
		aof日志存储的是redis服务器的顺序指令序列，只记录被内存进行修改的指令记录
		模式1:appendfsync always：每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢
		模式2:appendfsync no：不进行fsync，将flush文件的时机交给OS决定，速度最快
		模式3:appendfsync everysec：折中的做法，交由后台线程每秒fsync一次
		弊端:体量会变的很大(记录的是写操作) 恢复很慢
        优点:丢失数据少

        aof是文件存在 当redis发生写操作时需要对aof文件进行写操作 实际上时写道了一个内存缓存中 然后内存异步将其刷回磁盘
        但是如果突然宕机 会出现日志丢失

        fsync函数可以指定指定将文件的内容强制从缓存刷到磁盘 只要redis调用该函数就可以保证aof日志不丢失 但是fsync是一个磁盘操作

        很慢 所以需要权衡多久执行一次

        三种选择:1--永远不 让操作系统决定何时刷 2--一条指令刷一次 3--设置周期 一般在生产环境是每隔1s左右执行一次fsync

		4.0以前 重写aof 合并重复的指令 删除抵消的指令 最终还是一个纯指令的文件
		4.0以后 也是重写 发生重写之后混合rdb和aof  rdb+rdb(开始到结束之间产生的)aof 这样就会比单纯使用aof快很多

		AOF 后台执行的方式和 RDB 有类似的地方，fork 一个子进程，主进程仍进行服务
		子进程执行 AOF 持久化，数据被 dump 到磁盘上。与 RDB 不同的是，后台子进程持久化过程中
		主进程会记录期间的所有数据变更（主进程还在服务），并存储在 server.aof_rewrite_buf_blocks 中
		后台子进程结束后，redis 更新缓存追加到 AOF 文件中，是 RDB 持久化所不具备的.



		redis是先执行指令再将日志存盘 不同于其他存储引擎
		1--1.仅仅是因为，由于AOF文件会比较大，为了避免写入无效指令（错误指令）
		2--Redis 的数据是存内存的，断电之后就丢了 所以可以先执行，再记AOF
		3--redis的事务比起mysql等数据库的事务机制来说，可以称为弱事务 如果先写日志，同样会有很多无效命令。

	持久化主要在从节点进行
	
	redis4.0混合持久化
	将rdb文件的内容和增量的AOF日志文件存在一起，这里的AOF日志不再是全量的日志，而是至持久化开始到持久化结束的这段时间发生的
	增量AOF日志，通常这部分AOF日志很小

	单机 单节点 单实例
    1-单点故障
    2-容量有限
    3-压力

    主从复制
    主节点接受请求，进行读写 同步给从节点
    如何保持主从数据的同步
    强一致性:所需节点阻塞直到全部一致
    弱一致性:
    主节点异步同步数据到从节点 会丢失部分数据 redis使用的是这种
    最终一致性:主节点将数据写到中间容器，例如kafka(不是说redis就是这么干的)，客户端从kafka消费消息达到最终一致 hdfs使用的是这种

    n/2+1

    一般使用奇数台

    Cap

    Redis使用默认的异步复制，其特点是低延迟和高性能


   主从同步
   从节点刚加入近集群时，必须先进行一次快照同步
   快照同步:先在主节点做一次bgsave 将快照文件传输到从节点 从节点先删除old data，进行全量加载


   通过命令 replicaof 设置追随的主节点的地址


   旧版本的命令是slaveof

   主节点可以看到有哪些从节点连接上了

   从节点不想追随主节点，可以使用replicaof no one

   人工作方式重新选择新的主节点

   然后再将剩下的节点追随新的主节点

   增量同步
   主节点写入本地内存的buffer，buffer是有限的环形数组 如果因为网络问题，从节点和主节点无法同步，那么网络恢复时，有些在主节点中的增量指令已经被覆盖了 就需要快照同步

   在进行快照同步的时候如果时间过长或者buffer太小，会导致同步期间的增量指令被覆盖，导致快照结束狗无法进行增量复制，然后会再次发起快照同步 所以需要设置一个合适的buffer 避免快照复制的死循环


   通过一个配置文件 然后使用
   redis-server ./xx.conf --sentinel redis官网有一个最简版的配置 在redis的源码解压包里面也有一个默认的哨兵的配置文件


   启动三个redis实例 启动三个哨兵 杀掉主节点 哨兵会等待一段时间开启投票 多数投票投出新的主节点 其余的将追随新的主节点

   哨兵可以从主节点那里知道从节点的信息，那么是如何知道其他哨兵的信息的?

   是使用redis自带的发布订阅


3--redis过期策略
	方式一:惰性过期
		访问这个key的时候检查如果过期则立刻删除
	
	方式二:定时扫描(贪心策略)
		不会一次扫描过期字典中的所有的key
		1--从过期字典中随机选出20个key
		2--删除这20个key中已经过期的key
		3--如果过期的key的比例超过1/4，那就重复步骤1 
	扫描时间上限：25ms
	如果大量的key在统一时刻过期会导致客户端的请求会等待至少25ms后才进行处理
	如果客户端的超时时间设置的很短比如10ms，那么久会出现大量的链接因为超时而关闭	
	所以如果有大批量的key过期，要给过期时间设置一个随机范围，而不能全部在同一时间过期
		

	从节点:
	从节点不会进行过期扫描，主节点在key到期之后，会在AOF文件里增加一条del指令，同步
	所有的从节点
		
4--redis的内存淘汰策略
	策略1:noeviction.当内存不足以容纳新写入数据时，新写入操作会报错.读请求可以继续
	
	策略2:volatile-lru当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。

	策略3:volatile-random当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
	
	策略4:volatile-ttl 当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。
	
	策略5:allkeys-lru 当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。

	策略6:allkeys-random 当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。

5--管道
	本质:客户端通过改变了读写顺序带来的性能的巨大提升,和服务端没有什么直接关系
	客户端将请求传送给服务器，服务器处理完毕后，再将响应回复给客户端，这要花费一个网络数据包来回的时间
	如果连续执行多条指令，那么就会花费多个网络数据包来回的时间 write-->read---> write-->read
	如果调整读写顺序，write-- >write-->read-->read
	这样多个请求只会花费一次网络开销

	docker exec -it redis  redis-benchmark -t set -q 对普通的set进行压测 qps大约3w/s 阿里云服务器，1核2g


6--一个最简单的分布式锁
                "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
	这个lua脚本的意思是:获取redis中key为lockKey的值，如果和requestId相等的话则删除，否则啥都不做